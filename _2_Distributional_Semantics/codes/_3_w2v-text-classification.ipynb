{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitting-soccer",
   "metadata": {},
   "source": [
    "## The Problem: Large Movie Dataset Review\n",
    "### Classify movie reviews from IMDB into positive or negative sentiment.\n",
    "### Download the dataset [here](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a809a042-91c1-44ce-8756-91049863aa8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: tensorflow in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinated-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 11:46:21.284843: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-03 11:46:21.413004: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-03 11:46:21.484106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738583181.575441    2035 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738583181.598678    2035 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-03 11:46:21.802980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-washer",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "welsh-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 11:46:26.910280: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 11:46:45.391299: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-02-03 11:46:51.523259: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Importing & preprocessing the dataset\n",
    "\n",
    "train_ds = text_dataset_from_directory('../../Distributional_Semantics_Code_Files/aclImdb/train')\n",
    "test_ds = text_dataset_from_directory('../../Distributional_Semantics_Code_Files/aclImdb/test')\n",
    "\n",
    "dfTrain = pd.DataFrame(train_ds.unbatch().as_numpy_iterator(), columns=['text', 'label'])\n",
    "dfTest = pd.DataFrame(test_ds.unbatch().as_numpy_iterator(), columns=['text', 'label'])\n",
    "_, xts = train_test_split(dfTest, stratify=dfTest['label'], test_size=0.25)\n",
    "\n",
    "dfTrain['text'] = dfTrain['text'].map(lambda x: x.decode())\n",
    "xts['text'] = xts['text'].map(lambda x: x.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-visiting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28521</th>\n",
       "      <td>This work is a bold look into the mindset of men who find themselves in wheelchairs. This film never tries to tone it down, cotton candy-ize, or soft soap the angst, confusion, and pain of what th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>I seriously cannot think of why anyone would give this movie a 10/10. Sure we all have different taste in films, but to call this movie perfect is absurd in my opinion. I have nothing against the ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15672</th>\n",
       "      <td>E! TV is a great channel and Talk Soup is so funny,in a flash you can view the episodes change. We want more funny writings by the best writer ever Stan Evans.. The patron Saint of the mindless ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60925</th>\n",
       "      <td>This movie is not great, but it is a good and enjoyable one. It feels like an indie film made out of a play script. Morgan Freeman basically plays himself, although the director swears the script ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63543</th>\n",
       "      <td>This fun little romp into the world of billiards is just as good or better than many films I've seen in all the various video stores and yet I had to schmooze my way into obtaining a screener copy...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          text  \\\n",
       "28521  This work is a bold look into the mindset of men who find themselves in wheelchairs. This film never tries to tone it down, cotton candy-ize, or soft soap the angst, confusion, and pain of what th...   \n",
       "61187  I seriously cannot think of why anyone would give this movie a 10/10. Sure we all have different taste in films, but to call this movie perfect is absurd in my opinion. I have nothing against the ...   \n",
       "15672  E! TV is a great channel and Talk Soup is so funny,in a flash you can view the episodes change. We want more funny writings by the best writer ever Stan Evans.. The patron Saint of the mindless ma...   \n",
       "60925  This movie is not great, but it is a good and enjoyable one. It feels like an indie film made out of a play script. Morgan Freeman basically plays himself, although the director swears the script ...   \n",
       "63543  This fun little romp into the world of billiards is just as good or better than many films I've seen in all the various video stores and yet I had to schmooze my way into obtaining a screener copy...   \n",
       "\n",
       "       label  \n",
       "28521      1  \n",
       "61187      2  \n",
       "15672      1  \n",
       "60925      1  \n",
       "63543      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "dfTrain.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you're a guy you better wear a teflon jockstrap before going to this movie. It is a non stop male bashfest.<br /><br />Wear a fire proof suit to this drivel guys.<br /><br />The acting was bad.<br /><br />The story was ludicrous.<br /><br />Every scene was basically the same.<br /><br />A conversation among several women about how bad men suck.<br /><br />So, if you're feminist or a man hater you will love this gem.<br /><br />Whitney Houston was my favorite plastic statue in this one.<br /><br />I like Hale Berry but she never should have got roped into this.<br /><br />I'd love to have those 90 minutes back of my life.<br /><br />Please.\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-vault",
   "metadata": {},
   "source": [
    "## Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153845 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dfTrain['text'].tolist())\n",
    "train_sequences = tokenizer.texts_to_sequences(dfTrain['text'].tolist())\n",
    "test_sequences = tokenizer.texts_to_sequences(xts['text'].tolist())\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 330, 3, 225, 22, 125, 2396, 3, 47364, 87409, 164, 163, 5, 11, 17, 9, 6, 3, 691, 542, 899, 87410, 7, 7, 2396, 3, 1026, 3162, 1954, 5, 11, 3568, 457, 7, 7, 1, 116, 13, 74, 7, 7, 1, 63, 13, 2914, 7, 7, 172, 129, 13, 650, 1, 168, 7, 7, 3, 2434, 780, 434, 360, 41, 88, 74, 335, 2808, 7, 7, 36, 45, 330, 5532, 39, 3, 128, 18314, 22, 82, 112, 11, 1605, 7, 7, 11803, 8240, 13, 59, 523, 3008, 7156, 8, 11, 27, 7, 7, 10, 37, 7335, 6523, 18, 57, 111, 141, 25, 192, 18035, 78, 11, 7, 7, 487, 112, 5, 25, 144, 1524, 230, 140, 4, 59, 115, 7, 7, 594]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriental-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if', \"you're\", 'a', 'guy', 'you', 'better', 'wear', 'a', 'teflon', 'jockstrap', 'before', 'going', 'to', 'this', 'movie', 'it', 'is', 'a', 'non', 'stop', 'male', 'bashfest', 'br', 'br', 'wear', 'a', 'fire', 'proof', 'suit', 'to', 'this', 'drivel', 'guys', 'br', 'br', 'the', 'acting', 'was', 'bad', 'br', 'br', 'the', 'story', 'was', 'ludicrous', 'br', 'br', 'every', 'scene', 'was', 'basically', 'the', 'same', 'br', 'br', 'a', 'conversation', 'among', 'several', 'women', 'about', 'how', 'bad', 'men', 'suck', 'br', 'br', 'so', 'if', \"you're\", 'feminist', 'or', 'a', 'man', 'hater', 'you', 'will', 'love', 'this', 'gem', 'br', 'br', 'whitney', 'houston', 'was', 'my', 'favorite', 'plastic', 'statue', 'in', 'this', 'one', 'br', 'br', 'i', 'like', 'hale', 'berry', 'but', 'she', 'never', 'should', 'have', 'got', 'roped', 'into', 'this', 'br', 'br', \"i'd\", 'love', 'to', 'have', 'those', '90', 'minutes', 'back', 'of', 'my', 'life', 'br', 'br', 'please']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.index_word[k] for k in train_sequences[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subjective-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = max([max(map(len, train_sequences)), max(map(len, test_sequences))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "promising-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2493"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surgical-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sexual-convenience",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'if', \"you're\", 'a', 'guy', 'you', 'better', 'wear', 'a', 'teflon', 'jockstrap', 'before', 'going', 'to', 'this', 'movie', 'it', 'is', 'a', 'non', 'stop', 'male', 'bashfest', 'br', 'br', 'wear', 'a', 'fire', 'proof', 'suit', 'to', 'this', 'drivel', 'guys', 'br', 'br', 'the', 'acting', 'was', 'bad', 'br', 'br', 'the', 'story', 'was', 'ludicrous', 'br', 'br', 'every', 'scene', 'was', 'basically', 'the', 'same', 'br', 'br', 'a', 'conversation', 'among', 'several', 'women', 'about', 'how', 'bad', 'men', 'suck', 'br', 'br', 'so', 'if', \"you're\", 'feminist', 'or', 'a', 'man', 'hater', 'you', 'will', 'love', 'this', 'gem', 'br', 'br', 'whitney', 'houston', 'was', 'my', 'favorite', 'plastic', 'statue', 'in', 'this', 'one', 'br', 'br', 'i', 'like', 'hale', 'berry', 'but', 'she', 'never', 'should', 'have', 'got', 'roped', 'into', 'this', 'br', 'br', \"i'd\", 'love', 'to', 'have', 'those', '90', 'minutes', 'back', 'of', 'my', 'life', 'br', 'br', 'please']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.index_word.get(k, '<PAD>') for k in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-radius",
   "metadata": {},
   "source": [
    "# Train a classifier with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "human-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_wiki = KeyedVectors.load('wiki-countries.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "honey-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-02-03 11:47:11.337702: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78769152 exceeds 10% of free system memory.\n",
      "2025-02-03 11:47:11.398330: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78769152 exceeds 10% of free system memory.\n",
      "2025-02-03 11:47:11.414156: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78769152 exceeds 10% of free system memory.\n",
      "2025-02-03 11:47:11.648605: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 78769152 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = utils.make_embedding_layer(countries_wiki, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "countries_wiki_model = Sequential([\n",
    "    Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32'),\n",
    "    embedding_layer,\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "countries_wiki_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "married-slovakia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 11:47:12.235033: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 747900000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1668 - loss: -3177.1694 - val_accuracy: 0.5000 - val_loss: 50754.3086\n",
      "Epoch 2/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1661 - loss: -106295.6172 - val_accuracy: 0.5000 - val_loss: 356227.2500\n",
      "Epoch 3/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1659 - loss: -504480.2500 - val_accuracy: 0.5000 - val_loss: 1019355.4375\n",
      "Epoch 4/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.1635 - loss: -1289127.2500 - val_accuracy: 0.5000 - val_loss: 2089249.8750\n",
      "Epoch 5/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.1669 - loss: -2491455.2500 - val_accuracy: 0.5000 - val_loss: 3621101.0000\n",
      "Epoch 6/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1674 - loss: -4149669.2500 - val_accuracy: 0.5000 - val_loss: 5663783.5000\n",
      "Epoch 7/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.1679 - loss: -6405622.5000 - val_accuracy: 0.5000 - val_loss: 8253658.0000\n",
      "Epoch 8/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.1647 - loss: -9238769.0000 - val_accuracy: 0.5000 - val_loss: 11456716.0000\n",
      "Epoch 9/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1686 - loss: -12760957.0000 - val_accuracy: 0.5000 - val_loss: 15321568.0000\n",
      "Epoch 10/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1655 - loss: -16835738.0000 - val_accuracy: 0.5000 - val_loss: 19900494.0000\n",
      "Epoch 11/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.1660 - loss: -21339730.0000 - val_accuracy: 0.5000 - val_loss: 25263704.0000\n",
      "Epoch 12/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1681 - loss: -27332148.0000 - val_accuracy: 0.5000 - val_loss: 31414444.0000\n",
      "Epoch 13/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.1670 - loss: -33881024.0000 - val_accuracy: 0.5000 - val_loss: 38452004.0000\n",
      "Epoch 14/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.1671 - loss: -41204804.0000 - val_accuracy: 0.5000 - val_loss: 46408968.0000\n",
      "Epoch 15/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.1641 - loss: -49590224.0000 - val_accuracy: 0.5000 - val_loss: 55324876.0000\n",
      "Epoch 16/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1676 - loss: -58511060.0000 - val_accuracy: 0.5000 - val_loss: 65277032.0000\n",
      "Epoch 17/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.1683 - loss: -69031816.0000 - val_accuracy: 0.5000 - val_loss: 76283256.0000\n",
      "Epoch 18/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1675 - loss: -81462648.0000 - val_accuracy: 0.5000 - val_loss: 88376440.0000\n",
      "Epoch 19/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.1682 - loss: -93434464.0000 - val_accuracy: 0.5000 - val_loss: 101660712.0000\n",
      "Epoch 20/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.1654 - loss: -108259728.0000 - val_accuracy: 0.5000 - val_loss: 116161440.0000\n",
      "Epoch 21/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1676 - loss: -122868248.0000 - val_accuracy: 0.5000 - val_loss: 131939288.0000\n",
      "Epoch 22/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1669 - loss: -139163744.0000 - val_accuracy: 0.5000 - val_loss: 149040112.0000\n",
      "Epoch 23/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1677 - loss: -155654800.0000 - val_accuracy: 0.5000 - val_loss: 167480368.0000\n",
      "Epoch 24/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1664 - loss: -177497712.0000 - val_accuracy: 0.5000 - val_loss: 187309968.0000\n",
      "Epoch 25/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.1664 - loss: -196048720.0000 - val_accuracy: 0.5000 - val_loss: 208651920.0000\n",
      "Epoch 26/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1657 - loss: -218322880.0000 - val_accuracy: 0.5000 - val_loss: 231472288.0000\n",
      "Epoch 27/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.1658 - loss: -243782928.0000 - val_accuracy: 0.5000 - val_loss: 255785936.0000\n",
      "Epoch 28/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.1689 - loss: -264252144.0000 - val_accuracy: 0.5000 - val_loss: 281842976.0000\n",
      "Epoch 29/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.1692 - loss: -296616736.0000 - val_accuracy: 0.5000 - val_loss: 309437120.0000\n",
      "Epoch 30/30\n",
      "\u001b[1m1172/1172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.1666 - loss: -326746560.0000 - val_accuracy: 0.5000 - val_loss: 338711392.0000\n"
     ]
    }
   ],
   "source": [
    "countries_wiki_history = countries_wiki_model.fit(\n",
    "    train_data, dfTrain['label'].values,\n",
    "    validation_data=(test_data, xts['label'].values),\n",
    "    batch_size=64, epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-jersey",
   "metadata": {},
   "source": [
    "# Train with a different set of word embeddings\n",
    "\n",
    "## GloVe: Global Vectors for Word Representation\n",
    "### Download [here](http://nlp.stanford.edu/data/glove.6B.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "voluntary-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_wiki = KeyedVectors.load_word2vec_format('../../glove.6B.100d.txt', binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beginning-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = utils.make_embedding_layer(glove_wiki, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "glove_model = Sequential([\n",
    "    Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32'),\n",
    "    embedding_layer,\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "glove_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "identical-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1674 - loss: -10807.4434 - val_accuracy: 0.5000 - val_loss: 153175.8125\n",
      "Epoch 2/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1656 - loss: -302602.9062 - val_accuracy: 0.5000 - val_loss: 924432.8125\n",
      "Epoch 3/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.1681 - loss: -1298674.2500 - val_accuracy: 0.5000 - val_loss: 2515776.5000\n",
      "Epoch 4/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1679 - loss: -3200245.7500 - val_accuracy: 0.5000 - val_loss: 5113431.5000\n",
      "Epoch 5/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1673 - loss: -6160632.0000 - val_accuracy: 0.5000 - val_loss: 8921684.0000\n",
      "Epoch 6/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1675 - loss: -10366853.0000 - val_accuracy: 0.5000 - val_loss: 14112006.0000\n",
      "Epoch 7/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1671 - loss: -16248360.0000 - val_accuracy: 0.5000 - val_loss: 20847386.0000\n",
      "Epoch 8/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1663 - loss: -23757588.0000 - val_accuracy: 0.5000 - val_loss: 29343818.0000\n",
      "Epoch 9/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.1697 - loss: -33034682.0000 - val_accuracy: 0.5000 - val_loss: 39799140.0000\n",
      "Epoch 10/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1684 - loss: -43824224.0000 - val_accuracy: 0.5000 - val_loss: 52424192.0000\n",
      "Epoch 11/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1671 - loss: -57924112.0000 - val_accuracy: 0.5000 - val_loss: 67254168.0000\n",
      "Epoch 12/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1677 - loss: -73596976.0000 - val_accuracy: 0.5000 - val_loss: 84626216.0000\n",
      "Epoch 13/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1676 - loss: -93173544.0000 - val_accuracy: 0.5000 - val_loss: 104584792.0000\n",
      "Epoch 14/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1688 - loss: -112761144.0000 - val_accuracy: 0.5000 - val_loss: 127448800.0000\n",
      "Epoch 15/15\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1674 - loss: -138655648.0000 - val_accuracy: 0.5000 - val_loss: 153284096.0000\n"
     ]
    }
   ],
   "source": [
    "glove_history = glove_model.fit(\n",
    "    train_data, dfTrain['label'].values,\n",
    "    validation_data=(test_data, xts['label'].values),\n",
    "    batch_size=32, epochs=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interior-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x787f0e5a8bf0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(countries_wiki_history.history['val_accuracy'], label='Countries Wiki')\n",
    "plt.plot(glove_history.history['val_accuracy'], label='All Wiki')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
